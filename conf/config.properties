port = 8200
grid.mcp.address = 127.0.0.1:8100,yacygrid.com:8100
grid.ftp.address = anonymous:yacy@127.0.0.1:2121,anonymous:yacy@yacygrid.com:2121
grid.broker.address = anonymous:yacy@127.0.0.1:5672,anonymous:yacy@yacygrid.com:5672
grid.broker.lazy = true
grid.assets.delete = true

# The blacklist is choosen with the attribute grid.crawler.blacklist which gives the file name(s) of the blacklist(s) to be used.
# To use your own blacklist, create a file in data/crawler-8300/conf/ and set the name of it
# in the attribute grid.crawler.blacklist.
#
# You can use several blacklists simultanously, just comma-separate the names of the file names.
# all files in the path conf/ and data/crawler-8300/conf/ are found.
# The same applies to files in parallel processes like data/crawler-8301/conf/ and so on.
#
# The file format of the blacklist is:
# - it is a plain text file in UTF-8 encoding
# - every line beginning with '#' is a comment and is ignored
# - every string, matching with ' #.*' is removed. This cuts away comments from the end of a line.
# - every blank line is ignored
# - every other line must contain a regular expression according to
#   https://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html
#   which is considered as a matcher pattern (not a find pattern) for an URL.
#   Lines containing a regular expression get their leading and trailing spaces removed.
#
# All regular expressions are considered to be a disjunction (OR logic) for the filtering of cralwing urls.
# URLs are normalized before a matching is attempted, that means they are encoded propery
# and the fragment identifier is removed from the end of the URL.
grid.crawler.blacklist = crawler_blacklist_someonewhocares.txt,crawler_blacklist_localhost.txt,crawler_blacklist_vsm.txt
grid.indexer.blacklist = indexer_blacklist_filetypes.txt
grid.indexer.priorityQueues = 2
